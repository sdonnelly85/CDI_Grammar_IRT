---
title: Dimensionality of Vocabulary and Grammar (Full Data)
author: Seamus Donnelly
date: "`r Sys.Date()`"
output: 
  html_document:
    df_print: paged
    toc: true
    toc_float: true
    number_sections: true
---

This script examines whether the vocabulary and grammar sections of the CDI can be distinguished as separate dimensions^[This analysis considers all observations for which `longitudinal==false`. There are still many observations with the same values of `original_id`. Most of these appear to be participants who were tested at multiple time points as part of a data set that wasn't exclusively longitudinal. However the help file for Wordbank indicates that this variable is not always reliable. We have therefore also run this analysis on a subset of these data [withuut any duplicate original_ids]((https://rpubs.com/sdonnelly85/Grammar_Vocab_Dims_Reduced)))].  

Open the libraries. 
```{r message=FALSE, warning=FALSE}
options(max.print=500)
library(wordbankr) # WB data
library(tidyverse) # tidy
library(mirt) # IRT models
library(psych) # some psychometric stuff (tests of dimensionality)
library(Gifi)# some more psychometric stuff (tests of dimensionality)
library(knitr) # some formatting, tables, etc
library(lordif) # differential item functioning.
library(sirt) # additional IRT functions
```

# Data Preparation
```{r}
Inst <- get_instrument_data(language="English (American)", form="WS")
Admin <- get_administration_data(language="English (American)", form="WS")
N_total = nrow(Admin) # making sure things add up later
N_long = nrow(filter(Admin, longitudinal==TRUE)) # making sure things add up later
Item <- get_item_data(language="English (American)", form = "WS")
```

## Make Complexity Data
```{r}
Complex <- Admin %>%
  full_join(.,Inst, by="data_id") %>%
  full_join(., Item, by="num_item_id") %>%
  filter(longitudinal==FALSE) %>%
  filter(type == "combine" | # to drop non-combiners
           type == "complexity" # to calculate complexity scores.
         ) %>%
  mutate(
    out = ifelse(value=="complex" | value=="sometimes" | value=="produces", yes=1, 
                 no = ifelse(value=="often", yes=2, no =0))
  ) 

N_complexity_items = nrow(filter(Item, type == "combine" | 
           type == "complexity"))

nrow(Complex) == (N_total - N_long)*N_complexity_items
```

```{r}
Complex$complexity_category <- ifelse(Complex$complexity_category == "", yes=Complex$type, no=Complex$complexity_category)
```


```{r}
Complex_short_with_ids_all <- Complex %>% 
  dplyr::select(data_id, value, out, complexity_category, num_item_id) %>%
  mutate(
    label = str_c(complexity_category, num_item_id)
  ) %>%
  pivot_wider(id_cols=data_id, names_from = "label", values_from="out") %>%
  dplyr::select(starts_with(c("data_id", "combine", "morphology", "syntax"))) 

Complex_short_with_ids <- Complex_short_with_ids_all %>%  
drop_na()

N_NA <- nrow(Complex_short_with_ids_all) - nrow(Complex_short_with_ids)

Complex_short_grammatical <- Complex_short_with_ids %>%
  filter(combine760 > 0) %>%
  dplyr::select(starts_with(c("morphology", "syntax"))) # need to get rid of participant names for IRT models. 

N_nog <- nrow(filter(Complex_short_with_ids, combine760 == 0))

nrow(Complex_short_grammatical) == N_total - N_long - N_NA - N_nog
```

## Make Vocab Dataset
```{r}
Vocab <- Admin %>%
  full_join(.,Inst, by="data_id") %>%
  full_join(., Item, by="num_item_id") %>%
  filter(longitudinal==FALSE) %>% # remove longitudinal data set
  filter(type == "word"
         ) %>%
  mutate(
    out = ifelse(value=="produces", yes=1, no =0)
    )

N_vocab = nrow(filter(Item, type == "word")) 

nrow(Vocab) == (N_total - N_long)*N_vocab
```

```{r}
Vocab_short_with_ids_all <- Vocab %>% 
  filter(lexical_category == "nouns" | lexical_category == "predicates") %>%
  dplyr::select(data_id, value, out, definition) %>%
  pivot_wider(id_cols=data_id, names_from = "definition", values_from="out") 

Vocab_short_with_ids <- Vocab_short_with_ids_all %>%  
  drop_na() # drop participants with missing data

N_NA_Vocab = nrow(Vocab_short_with_ids_all) - nrow(Vocab_short_with_ids)

Vocab_short <- Vocab_short_with_ids %>%
  dplyr::select(-"data_id") # dataset for IRT can't have IDs

nrow(Vocab_short_with_ids) == N_total - N_long - N_NA_Vocab # Looks good
```


##Combine
```{r}
full <- full_join(
  Complex_short_with_ids, Vocab_short_with_ids, by="data_id"
) %>%
  filter(combine760 > 0) %>%
  dplyr::select(-c("data_id", "combine760")) %>%
  drop_na() # one participant with missing vocab, but full grammar. 
```


# Some quick checks of dimensionality. 

```{r}
full_tetra <- tetrachoric(full)

rho <- full_tetra$rho
```

```{r}
fa.parallel(rho, fa="fa", fm="minres", cor="poly", n.obs = 2187)
```

```{r}
vss(rho, fa="fa", fm="minres", cor="poly", n.obs = 2187)
```

# Try MIRT model.
```{r}
m1 <- mirt(full, 1, "2PL")
saveRDS(m1, "combined_irt_output/m1.rds")
m1 <-  readRDS("combined_irt_output/m1.rds")
```

Get factor scores
```{r}
fscores <- fscores(m1, use_dentype_estimate=TRUE)[,1]
```


```{r}
full2 <- data.frame(full)
```


##Confirmatory DETECT
```{r}
dtct <- c(rep(1, 37), rep(2, 478))

conf <- conf.detect(full2, fscores, dtct)
```

Does not seem like the 2-dimensional structure implied by the distinction between lexical items and grammatical items is justified. 

Exploratory detect to look for any other form of multidimensionality. 
```{r}
d1 <- expl.detect(full2, fscores, nclusters=2)
```

```{r}
options(max.print=2000)
d1
```





